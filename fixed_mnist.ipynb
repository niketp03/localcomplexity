{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad9307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as ch\\n\n",
    "import torchvision\\n\n",
    "from torchvision import transforms\\n\n",
    "from torch.nn import CrossEntropyLoss\\n\n",
    "from torch.optim import SGD, lr_scheduler, AdamW\\n\n",
    "from torch.func import jacfwd, jacrev\\n\n",
    "from torch import vmap\\n\n",
    "import numpy as np\\n\n",
    "from torch import nn\\n\n",
    "import torch as ch\\n\n",
    "import einops\\n\n",
    "\\n\n",
    "from attacks import PGD\\n\n",
    "\\n\n",
    "import ml_collections\\n\n",
    "from tqdm import tqdm\\n\n",
    "import os\\n\n",
    "import time\\n\n",
    "import logging\\n\n",
    "\\n\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6ba8b2",
   "metadata": {},
   "source": [
    "# Configuration Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241e2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\\n\n",
    "  \\\n",
    "\\\n",
    "\\\n",
    "\\n\n",
    "  config = ml_collections.ConfigDict()\\n\n",
    "\\n\n",
    "  config.optimizer = 'adam'\\n\n",
    "  config.lr = 1e-4\\n\n",
    "  config.momentum = 0.01\\n\n",
    "  config.bias_decay = False\\n\n",
    "\\n\n",
    "  config.train_batch_size = 64 #256\\n\n",
    "  config.test_batch_size = 64 #256\\n\n",
    "\\n\n",
    "  config.num_steps = 1000000                       # number of training steps\\n\n",
    "  config.weight_decay = 0.01\\n\n",
    "\\n\n",
    "  config.label_smoothing = 0.0\\n\n",
    "\\n\n",
    "  config.log_steps = np.unique(\\n\n",
    "      np.logspace(0,np.log10(config.num_steps),50).astype(int).clip(\\n\n",
    "          0,config.num_steps\\n\n",
    "          )\\n\n",
    "      )\\n\n",
    "  \\n\n",
    "  config.seed = 42\\n\n",
    "\\n\n",
    "  #config.dmax = 1\\n\n",
    "  #config.dmin = 0\\n\n",
    "\\n\n",
    "  config.wandb_proj = 'LRLC_study_MNIST_MLP'\\n\n",
    "  config.wandb_pref = 'MNIST-MLP'\\n\n",
    "\\n\n",
    "  config.resume_step = 0\\n\n",
    "\\n\n",
    "  ## mlp params\\n\n",
    "  config.input_dim = 784\\n\n",
    "  config.output_dim = 10\\n\n",
    "  config.hidden_dim = 200\\n\n",
    "  config.n_layers = 4\\n\n",
    "  config.input_weights_init_scale = np.sqrt(2) #sets initialization standard deviation to be = (input_weights_init_scale)/sqrt(input_dim) \\n\n",
    "  config.output_weights_init_scale = np.sqrt(2)\\n\n",
    "\\n\n",
    "\\n\n",
    "  ## local complexity approx. parameters\\n\n",
    "  config.compute_LC = True\\n\n",
    "  config.n_batches = 2\\n\n",
    "  config.sigma = 0.01\\n\n",
    "  config.n_iters_LC = 1\\n\n",
    "\\n\n",
    "  ## adv robustness parameters\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f119998f",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cb6e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\\n\n",
    "import random\\n\n",
    "\\n\n",
    "train_dataset = torchvision.datasets.MNIST('../mnist_data',\\n\n",
    "                                           download=True,\\n\n",
    "                                           train=True,\\n\n",
    "                                           transform=transforms.Compose([\\n\n",
    "                                               transforms.ToTensor(), # first, convert image to PyTorch tensor\\n\n",
    "                                               transforms.Normalize((0.1307,), (0.3081,)), # normalize inputs\\n\n",
    "                                               lambda x: einops.rearrange(x, 'c h w -> (c h w)') # flatten the input images\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc4b4cb",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d60d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\\n\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, input_std_init=1, output_std_init=1):\\n\n",
    "        super(MLP, self).__init__()\\n\n",
    "        self.input_dim = input_dim\\n\n",
    "        self.output_dim = output_dim\\n\n",
    "        self.n_layers = n_layers\\n\n",
    "\\n\n",
    "        # Define input layer\\n\n",
    "        self.layers = nn.ModuleList()\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad0fe00",
   "metadata": {},
   "source": [
    "# Eval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e8a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ch.no_grad\\n\n",
    "def evaluate(model, dloader, loss_fn=None):\\n\n",
    "  \\n\n",
    "  model.eval()\\n\n",
    "\\n\n",
    "  acc = 0\\n\n",
    "  loss = 0\\n\n",
    "  nsamples = 0\\n\n",
    "  nbatch = 0\\n\n",
    "  \\n\n",
    "  for inputs, targets in dloader:\\n\n",
    "      \\n\n",
    "      inputs = inputs.cuda()\\n\n",
    "      targets = targets.cuda()\\n\n",
    "      outputs = model(inputs)\\n\n",
    "\\n\n",
    "      if loss_fn is not None:\\n\n",
    "        loss += loss_fn(outputs, targets).item()\\n\n",
    "        nbatch += 1\\n\n",
    "              \\n\n",
    "      acc += ch.sum(targets == outputs.argmax(dim=-1)).cpu()\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fcfb12",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba17201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loaders, config):\\n\n",
    "    print('Training....')\\n\n",
    "    print(f'Logging at steps: {config.log_steps}')\\n\n",
    "\\n\n",
    "    model.cuda()\\n\n",
    "\\n\n",
    "    # No Weight Decay on Biases\\n\n",
    "    decay = dict()\\n\n",
    "    no_decay = dict()\\n\n",
    "    for name, param in model.named_parameters():\\n\n",
    "        print('checking {}'.format(name))\\n\n",
    "        if 'weight' in name:\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8e4fed",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3adba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_project = config.wandb_proj\\n\n",
    "timestamp = time.ctime().replace(' ','_')\\n\n",
    "wandb_run_name = f\\\n",
    "\\n\n",
    "wandb.init(project=wandb_project, name=wandb_run_name, config=config)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
